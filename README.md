# ğŸ§  General Vision Framework (GVF)

> **A unified, modular, and extensible deep learning framework** for computer vision â€” supporting classification, segmentation, self-supervised learning, anomaly detection, and meta-learning â€” all built on TensorFlow 2.x, fully config-driven, registry-based, and designed for reproducibility and deployment.

---

## ğŸš€ Overview

This framework was built for **high-performance visual learning** tasks such as:
- **Defect detection** (supervised, self-supervised, and anomaly-based)
- **Semantic segmentation**
- **Representation learning** (SimCLR, SupCon)
- **Meta-learning and few-shot learning** (ProtoNet, MAML)
- **Lightweight deployment and compression**

It emphasizes:
- ğŸ§© **Modularity** â€“ every component is plug-and-play  
- âš™ï¸ **Config-driven orchestration** â€“ no code changes required  
- ğŸ§  **Stable training and reproducibility**  
- ğŸ“Š **Continuous diagnostics and auto-reporting**  
- ğŸš€ **Production-ready export and inference**

---

## ğŸ“‚ Project Structure

```
cv_framework/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ base_model.py              # Abstract base for all models
â”‚   â”œâ”€â”€ base_dataset.py            # Unified dataset interface
â”‚   â”œâ”€â”€ builder.py                 # Builds from YAML configs
â”‚   â”œâ”€â”€ registry.py                # Global registries
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ seed_utils.py
â”‚   â”‚   â”œâ”€â”€ memory_utils.py        # Memory management
â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â””â”€â”€ metrics.py
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ backbones/
â”‚   â”‚   â”œâ”€â”€ lightcnn_tf.py
â”‚   â”‚   â”œâ”€â”€ model_components.py    # Modular CNN, Residual, Attention blocks
â”‚   â”œâ”€â”€ segmentation/
â”‚   â”‚   â”œâ”€â”€ base_segmentation.py
â”‚   â”‚   â”œâ”€â”€ unet_tf.py
â”‚   â”‚   â””â”€â”€ (DeepLab, UNet++ etc.)
â”‚   â”œâ”€â”€ self_supervised/
â”‚   â”‚   â”œâ”€â”€ simclr_tf.py
â”‚   â”‚   â”œâ”€â”€ supcon_tf.py
â”‚   â”œâ”€â”€ anomaly/
â”‚   â”‚   â”œâ”€â”€ autoencoder_tf.py
â”‚   â”‚   â”œâ”€â”€ ganomaly_tf.py
â”‚   â”‚   â””â”€â”€ fanogan_tf.py
â”‚   â”œâ”€â”€ meta_learning/
â”‚   â”‚   â”œâ”€â”€ base_meta.py
â”‚   â”‚   â”œâ”€â”€ protonet_tf.py
â”‚   â”‚   â””â”€â”€ maml_tf.py
â”‚   â””â”€â”€ builders/
â”‚       â””â”€â”€ model_builder.py       # YAML/JSON design builder
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â”œâ”€â”€ defect_dataset_tf.py
â”‚   â”œâ”€â”€ meta_tasks/
â”‚   â”‚   â””â”€â”€ episodic_loader_tf.py
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ base_trainer.py
â”‚   â”œâ”€â”€ hypersearch/
â”‚   â”‚   â”œâ”€â”€ optuna_search.py
â”‚   â”‚   â”œâ”€â”€ grid_search.py
â”‚   â”‚   â””â”€â”€ random_search.py
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ sanity_checks/
â”‚   â”‚   â”œâ”€â”€ generic.py
â”‚   â”‚   â”œâ”€â”€ ssl_checks.py
â”‚   â”‚   â”œâ”€â”€ anomaly_checks.py
â”‚   â”‚   â”œâ”€â”€ meta_checks.py
â”‚   â”‚   â”œâ”€â”€ diagnostics_manager.py
â”‚   â”‚   â”œâ”€â”€ visualization_utils.py
â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â””â”€â”€ report_generator.py
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ manager/
â”‚   â”‚   â”œâ”€â”€ experiment_manager.py
â”‚   â”‚   â”œâ”€â”€ environment_utils.py
â”‚   â”‚   â”œâ”€â”€ tracker.py
â”‚   â”‚   â””â”€â”€ run_summary.py
â”‚
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ exporter_tf.py
â”‚   â”œâ”€â”€ compression_utils.py
â”‚   â”œâ”€â”€ version_manager.py
â”‚   â”œâ”€â”€ inference_api.py
â”‚   â””â”€â”€ compression_report.py
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ train_lightcnn.yaml
â”‚   â”œâ”€â”€ train_unet.yaml
â”‚   â”œâ”€â”€ train_supcon.yaml
â”‚   â”œâ”€â”€ train_autoencoder.yaml
â”‚   â”œâ”€â”€ train_protonet.yaml
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ light_cnn_design.yaml
â”‚   â”‚   â”œâ”€â”€ unet_encoder.yaml
â”‚   â”‚   â”œâ”€â”€ unet_decoder.yaml
â”‚   â”‚   â”œâ”€â”€ discriminator_basic.yaml
â”‚   â”‚   â””â”€â”€ projection_head.yaml
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ export_model.py
â”‚   â””â”€â”€ run_hypersearch.py
â”‚
â””â”€â”€ README.md
```

---

## ğŸ§© Core Features

### ğŸ”§ **Registry + Config-Driven Architecture**
- Every model, dataset, loss, optimizer, and scheduler is registered via decorators.
- All experiments are defined in YAML (no code edits).

```python
@MODEL_REGISTRY.register("lightcnn")
class LightCNN(BaseModel): ...
```

---

### ğŸ§± **Reusable Building Blocks (`model_components.py`)**
Includes:
- `ConvBlock`, `ResidualBlock`, `DenseBlock`
- `SEBlock`, `CBAM`, `SelfAttention2D`, `SpatialAttentionLite`
- Fully compatible with YAML-based designs.

> **Performance Gains:** Attention modules improve representation focus and convergence stability (Hu et al., 2018; Woo et al., 2018; Wang et al., 2018).

---

### ğŸ§  **Supported Model Families**
| Category | Examples | Notes |
|-----------|-----------|-------|
| Classification | LightCNN, MobileNet | Lightweight backbones |
| Segmentation | U-Net, YAML-based encoder/decoder | Supports Dice, Focal, Tversky |
| SSL | SimCLR, SupCon, BYOL | Modular projection heads |
| Anomaly | Autoencoder, GANomaly, f-AnoGAN | Design-driven encoders/decoders |
| Meta-learning | ProtoNet, MAML, Reptile | Uses episodic loaders |
| Attention | SEBlock, CBAM, Self-Attention | Drop-in YAML layers |

---

### ğŸ” **Hyperparameter & Architecture Search**
- Integrated **Optuna**, **Grid**, and **Random** search.
- Architecture-level NAS via YAML design swapping.
- Automatic logging of best trials under `experiments/hypersearch/`.

---

### ğŸ“Š **Diagnostics & Continuous Evaluation**
- Built-in sanity checks for every model type:
  - Gradient health, forward pass, overfit-one-batch
  - SSL: Inter/intra-class embedding distances
  - Anomaly: Reconstruction loss visualization
  - Meta: Prototype embedding plots
- Continuous diagnostics every *N* epochs (TensorBoard + PDF reports).

---

### ğŸ’¾ **Experiment Management & Tracking**
- Environment snapshot (`environment.json`)
- Config archive (`config_snapshot.json`)
- Training logs (TensorBoard + JSON)
- Auto-generated run summaries
- Parallel multi-config orchestration

---

### âš¡ **Memory & Resource Management**
- `clear_tf_memory()` prevents GPU memory leaks.
- Dataset cache clearing for sequential runs.
- Optional GPU monitor for diagnostics.

---

### ğŸ§¬ **Compression & Deployment**
- Pruning, Quantization (INT8), Clustering.
- TF SavedModel, ONNX, and TFLite export.
- Unified inference API (`inference_api.py`):
  ```python
  api = InferenceAPI(config_path, weights_path)
  preds = api.classify_image("sample.jpg")
  ```

> Compression typically yields **4â€“10Ã— smaller models**, **1.5â€“3Ã— faster inference**, â‰¤1â€“2% accuracy change (Han et al., 2015; Jacob et al., 2018).

---

### ğŸ§  **Reproducibility**
- Random seed control  
- Full environment capture  
- Config + code version snapshots  
- Model registry versioning (`model_registry.json`)

---

## ğŸ§© Typical Workflow

1. **Design the architecture**
   ```yaml
   configs/models/my_custom_design.yaml
   ```
2. **Define experiment config**
   ```yaml
   configs/train_custom.yaml
   ```
3. **Run training**
   ```bash
   python scripts/train.py --config configs/train_custom.yaml
   ```
4. **Run diagnostics**
   ```bash
   tensorboard --logdir experiments/runs/
   ```
5. **Compress & export**
   ```bash
   python scripts/export_model.py --config experiments/runs/<run>/config_snapshot.json
   ```
6. **Deploy for inference**
   ```python
   from deployment.inference_api import InferenceAPI
   api = InferenceAPI("config.yaml", "final_model/variables/variables")
   api.predict(input_tensor)
   ```

---

## ğŸ“š References

- Hu, J., Shen, L., & Sun, G. (2018). *Squeeze-and-Excitation Networks.* CVPR.  
- Woo, S., Park, J., Lee, J. Y., & Kweon, I. S. (2018). *CBAM: Convolutional Block Attention Module.* ECCV.  
- Wang, X. et al. (2018). *Non-local Neural Networks.* CVPR.  
- Han, S. et al. (2015). *Deep Compression.* NIPS.  
- Jacob, B. et al. (2018). *Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference.* CVPR.  

---

## âœ… Summary

**You now have a unified TensorFlow 2.x framework** for:
- ğŸ§± Modular deep learning experiments  
- ğŸ§© Extensible vision architectures  
- ğŸ“Š Continuous diagnostics and automatic reporting  
- âš™ï¸ Automated search and orchestration  
- ğŸš€ Deployment-ready compression and export  

This foundation can be extended indefinitely â€” from attention-based segmentation to contrastive meta-learning â€” all through configuration files, not rewrites.
